---
title: "Towards reproducibility in small-N treatment research in aphasiology: a tutorialy"
output : pdf_document
---

```{r setup, include = FALSE}
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

This document details the code batch calculate effect sizes.  

# Setup 

## Load packages and functions

```{r}
library(here)           # for locating files
library(GGally)         # Plotting
library(SingleCaseES)   # calculating SMD, Tau-U
library(lme4)           # frequentist mixed-effects models
library(emmeans)        # estimating effect sizes from lme4
library(brms)           # bayesian mixed-effects models
library(tidybayes)      # estimating effect sizes from brms
library(ggdist)         # Visualizing posterior distributions
library(tidyverse)      # data wrangling and plotting

# set a seed for reproducibility
set.seed(42)

source(here("R", "effect-size-functions.R"))    

```

## Read in data

\noindent Note that the current setup uses RStudio R projects (https://support.rstudio.com/hc/en-us/articles/200526207-Using-RStudio-Projects). One of the
features of R projects is that the working directory is automatically set to the project root (the folder with the .Rproj). A discussion of R projects can be found at https://www.tidyverse.org/blog/2017/12/workflow-vs-script/. In this case `here("study-data")` refers to the /study-data folder inside the project. 


```{r}
# create a list of files
files <- list.files(
                 here("study-data"), # look in the study-data folder
                 full.names = TRUE,  # use the full paths of the files
                 pattern = ".csv",   # only read in .csv files
                 recursive = TRUE)   # include files within subfolders

# read in the files and combine them together
# map_df takes a function, in this case read_csv().
# show_col_types suppresses output sinc we're reading in many files
df <- files %>%
  map_dfr(read_csv, show_col_types = FALSE)

```

# Calculate effect sizes


## *d*~BR~

```{r}
df_smd = df %>%
  filter(phase == "baseline" | phase == "treatment") %>%
  group_by(participant, phase, condition, itemType, session,
           spt2017, trials, phoneme) %>%
  summarize(correct = sum(response),
            trials = unique(trials), .groups = "drop") %>%
  nest_by(participant, condition, itemType) %>%
  summarize(SMD_br(data), .groups = "drop")
```

## PMG

```{r}
df_pmg = df %>%
  filter(spt2017 == "pre" | spt2017 == "post" ) %>%
  group_by(participant, phase, condition, itemType, session,
           spt2017, trials) %>%
  summarize(correct = sum(response),
            trials = unique(trials)*2, .groups = "drop") %>%
  group_by(participant, condition, itemType) %>%
  summarize(PMG(outcome = correct, phase = spt2017, nitems = trials,
                bl_phase = "pre", tx_phase = "post"), .groups = "drop")
```

## Tau-U

```{r}
df_tau = df %>%
  filter(phase == "baseline" | phase == "treatment") %>%
  group_by(participant, phase, condition, itemType, session) %>%
  summarize(correct = sum(response), .groups = "drop") %>%
  group_by(participant, condition, itemType) %>%
  summarize(Tau_custom(outcome = correct, phase = phase, 
                       bl_phase = "baseline", tx_phase = "treatment",
                       session = session, cutoff = 0.33), .groups = "drop")
```

## Bayesian Mixed-effects models

\noindent Setup data

```{r}
df_itts_group = df %>%
  filter(phase == "baseline" | phase == "treatment") %>%
  mutate(baseline_slope = session,
         level_change = ifelse(phase == "baseline", 0, 1),
         slope_change = (session - (n_baselines+2))*level_change) %>%
  select(response, participant, condition, itemType, phase,
         phoneme, item, baseline_slope, level_change, slope_change) 
```

```{r, include = FALSE}

# df_itts_group = df %>%
#   filter(phase == "baseline" | phase == "treatment") %>%
#   left_join(bl_sessions, by = c("participant", "itemType", "condition")) %>%
#   mutate(baseline_slope = session,
#          level_change = ifelse(phase == "baseline", 0, 1),
#          slope_change = (session - (max_bl+2))*level_change,
#          obs = 1) %>%
#   select(response, participant, condition, itemType, phase,
#          trials, baseline_slope, level_change, slope_change, obs) %>%
#   group_by(baseline_slope, level_change, slope_change, participant, condition, itemType) %>%
#   summarize(correct = sum(response),
#             trials = sum(obs)) 
```


### Blocked Treated

```{r}

  mod_tx_bl <- brm(
    response ~ 0 + Intercept + baseline_slope + level_change + slope_change + 
               (1 + baseline_slope + level_change + slope_change | participant) +
               (1| item),
             data = df_itts_group %>% filter(condition == "blocked",
                                             itemType == "tx"),
             family = bernoulli(),
             iter = 3000,
             warmup = 1000,
             cores = 4, chains = 4,
             prior = c(
               prior(normal(-1, 2.5), class = b, coef = Intercept),
               prior(normal(0, 2.5), class = b)
             ),
             control = list(adapt_delta = 0.9),
             seed = 42,
             file = "models/mod_tx_bl",
             file_refit = "on_change"
  )
```

### Blocked Generalization

```{r}
  
  mod_gx_bl <- brm(
    response ~ 0 + Intercept + baseline_slope + level_change + slope_change + 
               (1 + baseline_slope + level_change + slope_change | participant) +
               (1| item),
                   data = df_itts_group %>% filter(condition == "blocked",
                                                   itemType == "gx"),
                   family = bernoulli(),
                   iter = 3000,
                   warmup = 1000,
                   cores = 4, chains = 4,
                   prior = c(
                     prior(normal(-1, 2.5), class = b, coef = Intercept),
                     prior(normal(0, 2.5), class = b)
                   ),
                   control = list(adapt_delta = 0.85),
                   seed = 42,
                   file = "models/mod_gx_bl",
                   file_refit = "on_change"
  )
  
```

### Random Treated

```{r}
  mod_tx_ra <- brm(
    response ~ 0 + Intercept + baseline_slope + level_change + slope_change + 
               (1 + baseline_slope + level_change + slope_change | participant) +
               (1| item),
                   data = df_itts_group %>% filter(condition == "random",
                                                   itemType == "tx"),
                   family = bernoulli(),
                   iter = 3000,
                   warmup = 1000,
                   cores = 4, chains = 4,
                   prior = c(
                     prior(normal(-1, 2.5), class = b, coef = Intercept),
                     prior(normal(0, 2.5), class = b)
                   ),
                   seed = 42,
                   control = list(adapt_delta = 0.85),
                   file = "models/mod_tx_ra",
                   file_refit = "on_change"
  )
  
```

### Random Generalization

```{r}
  mod_gx_ra <- brm(
    response ~ 0 + Intercept + baseline_slope + level_change + slope_change + 
               (1 + baseline_slope + level_change + slope_change | participant) +
               (1| item),
                   data = df_itts_group %>% filter(condition == "random",
                                                   itemType == "gx"),
                   family = bernoulli(),
                   iter = 3000,
                   warmup = 1000,
                   cores = 4, chains = 4,
                   control = list(adapt_delta = 0.9),
                   prior = c(
                     prior(normal(-1, 2), class = b, coef = Intercept),
                     prior(normal(0, 2), class = b)
                   ),
                   seed = 42,
                   file = "models/mod_gx_ra",
                   file_refit = "on_change"
  )
  
```

# Pull the effect sizes together and plot

```{r}
es_tx_bl = getES(mod_tx_bl, "tx", "blocked")
es_tx_ra = getES(mod_tx_ra, "tx", "random")
es_gx_bl = getES(mod_gx_bl, "gx", "blocked")
es_gx_ra = getES(mod_gx_ra, "gx", "random")

smd = 
  df_smd %>%
  select(participant, condition, itemType, SMD, SMD_all, sd1, sd2)

pmg = 
  df_pmg %>%
  select(participant, condition, itemType, PMG, raw_change = raw_change_exit, baseline_score)

tau = 
  df_tau %>%
  select(participant, condition, itemType, Tau = Est)

bglmm = 
  bind_rows(es_tx_bl, es_tx_ra, es_gx_bl, es_gx_ra) %>%
  select(participant, ES, unit, itemType, condition) %>%
  pivot_wider(names_from = unit, values_from = ES) %>%
  rename(glmm_logit = logit, glmm_percent = pred)

es = smd %>%
  left_join(pmg, by = c("participant", "itemType", "condition")) %>%
  left_join(tau, by = c("participant", "itemType", "condition")) %>%
  left_join(bglmm, by = c("participant", "itemType", "condition")) %>%
  relocate(raw_change, .after = last_col()) %>%
  relocate(SMD_all, .before = last_col()) %>%
  mutate(itemType = factor(itemType, levels = c("tx", "gx")))
```

## Plot comparisons

```{r, warning = FALSE}
# p3 = ggpairs(es %>% select(-VAR1, -VAR2, -baseline_score),
#         columns = 4:8,
#         mapping = aes(fill = itemType, color = itemType),
#         columnLabels = c("d[BR]", "PMG", "T~au-U", "GLMM~Logit", "GLMM~Percent"),
#         labeller = "label_parsed",
#          diag = list(discrete="barDiag", 
#                            continuous = wrap("densityDiag", alpha=0.5, color = "grey50" )), 
#                upper = list(#combo = wrap("box_no_facet", alpha=0.5),
#                             continuous = wrap(ggally_cor, stars = F, digits = 2)),
#         lower = list(continuous = wrap("points", alpha = 0.7, pch=21, color="grey40", size=1.5)))
# 
# dropLeadingZero <- function(l){
#   lnew <- c()
#   for(i in l){
#     if(i==0){ #zeros stay zero
#       lnew <- c(lnew,"0")
#     } else if (i>1){ #above one stays the same
#       lnew <- c(lnew, as.character(i))
#     } else
#       lnew <- c(lnew, gsub("(?<![0-9])0+", "", i, perl = TRUE))
#   }
#   as.character(lnew)
# }
# 
# 
# p3[2,1] = p3[2,1] + scale_x_continuous(breaks = seq(0, 15, 3))
# p3[3,1] = p3[3,1] + scale_x_continuous(breaks = seq(0, 15, 3))
# p3[4,1] = p3[4,1] + scale_x_continuous(breaks = seq(0, 15, 3))
# p3[5,1] = p3[5,1] + scale_x_continuous(breaks = seq(0, 15, 3))
# 
# p3[3,2] = p3[3,2] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25))
# p3[4,2] = p3[4,2] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25))
# p3[5,2] = p3[5,2] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25))
# 
# p3[4,3] = p3[4,3] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25))
# p3[5,3] = p3[5,3] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25))
# 
# p3[5,4] = p3[5,4] + scale_x_continuous(breaks = seq(0, 10, 2))
# 
# p3[5,5] = p3[5,5] + scale_x_continuous(labels = dropLeadingZero, breaks = seq(0, 1, 0.25), limits = c(0,1))
# 
# ggsave(p3, filename = here("manuscript", "p3.png"), bg = "white", width = 7, height = 6, dpi = 400)

```


```{r, include = FALSE}
# 
#   es %>% ungroup() %>%
#   select(3:8) %>%
#   mutate(itemType = factor(
#     ifelse(itemType == "gx", "Generalization", "Treated"),
#     levels = c("Treated", "Generalization"))) %>%
#   gtsummary::tbl_summary(by="itemType",
#               missing_text = "N/A",
#               statistic = list(gtsummary::all_continuous() ~ "{median} ({min}, {max})"))
```


```{r, include = FALSE}

es_tx_bl_adjust = getES(mod_tx_bl, "tx", "blocked", adjust = TRUE)
es_tx_ra_adjust = getES(mod_tx_ra, "tx", "random", adjust = TRUE)
es_gx_bl_adjust = getES(mod_gx_bl, "gx", "blocked", adjust = TRUE)
es_gx_ra_adjust = getES(mod_gx_ra, "gx", "random", adjust = TRUE)

bglmm_adjust = 
  bind_rows(es_tx_bl_adjust, es_tx_ra_adjust, es_gx_bl_adjust, es_gx_ra_adjust) %>%
  select(participant, ES, unit, itemType, condition) %>%
  pivot_wider(names_from = unit, values_from = ES) %>%
  rename(glmm_logit_a = logit, glmm_percent_a = pred)


pmg_all = df %>%
  filter(phase == "baseline" | phase == "treatment" & spt2017 == "post") %>%
  group_by(participant, phase, condition, itemType, session,
           spt2017, trials) %>%
  summarize(correct = sum(response),
            trials = unique(trials)*2, .groups = "drop") %>%
  group_by(participant, condition, itemType) %>%
  summarize(PMG(outcome = correct, phase = phase, nitems = trials,
                bl_phase = "baseline", tx_phase = "treatment"), .groups = "drop") %>%
  select(participant, condition, itemType, PMG_all = PMG, raw_change_all = raw_change_exit, baseline_score_all = baseline_score)

tau = 
  df_tau %>%
  select(participant, condition, itemType, Tau = Est)

tau2 = df %>%
  filter(phase == "baseline" | phase == "treatment") %>%
  group_by(participant, phase, condition, itemType, session) %>%
  summarize(correct = sum(response), .groups = "drop") %>%
  group_by(participant, condition, itemType) %>%
  summarize(Tau_custom(outcome = correct, phase = phase, 
                       bl_phase = "baseline", tx_phase = "treatment",
                       session = session, cutoff = 0.4), .groups = "drop") %>%
  select(participant, condition, itemType, Tau_4 = Est)


es = smd %>%
  left_join(pmg, by = c("participant", "itemType", "condition")) %>%
  left_join(tau, by = c("participant", "itemType", "condition")) %>%
  left_join(bglmm, by = c("participant", "itemType", "condition")) %>%
  left_join(bglmm_adjust, by = c("participant", "itemType", "condition")) %>%
  left_join(pmg_all, by = c("participant", "itemType", "condition")) %>%
  left_join(tau2, by = c("participant", "itemType", "condition")) %>%
  relocate(raw_change, .after = last_col()) %>%
  relocate(SMD_all, .before = last_col()) %>%
  mutate(itemType = factor(itemType, levels = c("tx", "gx")))

write.csv(es, here("shiny", "effect-sizes.csv"), row.names = FALSE)
write.csv(df, here("shiny", "data.csv"), row.names = FALSE)
```


